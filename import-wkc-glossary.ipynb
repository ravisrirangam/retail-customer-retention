{
    "cells": [
        {
            "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='87902905-49b0-44e8-92e8-c71cac62c598', project_access_token='p-4d7a4110eed802e92082e9f0fab0e8b34ef7f160')\n",
            "cell_type": "code",
            "execution_count": null,
            "outputs": [],
            "metadata": {}
        },
        {
            "metadata": {
                "id": "985eb7f2-53d2-464d-8e13-69a44ed1a2e6"
            },
            "cell_type": "markdown",
            "source": "# Import and Map Business Terms to Data Headers"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "\nBefore executing this notebook on IBM Cloud , you need to:<br>\n1) When you import this project on an IBM Cloud environment, a project access token should be inserted at the top of this notebook as a code cell. <br>\nIf you do not see the cell above, Insert a project token: Click on **More -> Insert project token** in the top-right menu section and run the cell <br>\n\n![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n2) Provide your IBM Cloud API key in the subsequent cell<br>\n3) You can then step through the notebook execution cell by cell, by selecting Shift-Enter. Or you can execute the entire notebook by selecting **Cell -> Run All** from the menu.<br>\n\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Insert IBM Cloud API key\nYour Cloud API key can be generated by going to the <a href=\"https://cloud.ibm.com/iam/apikeys\" target=\"_blank\" rel=\"noopener noreferrer\">API Keys section of the Cloud console</a>. From that page, scroll down to the API Keys section, and click Create an IBM Cloud API key. Give your key a name and click Create, then copy the created key and paste it below. \n\nCloud API key will be used to authenticate Watson Knowledge Catalog services."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ibmcloud_api_key=''",
            "execution_count": 27,
            "outputs": []
        },
        {
            "metadata": {
                "id": "b53c49c2-e33b-44f6-8d83-5d7ba662330e"
            },
            "cell_type": "markdown",
            "source": "## Introduction\nThis notebook imports a business glossary for the industry accelerator into Watson Knowledge Catalog (WKC) for use in governing data assets. It also connects the data assets used in the accelerator to the WKC business terms.\n\nIn the first part of the notebook category and business terms are imported and then business terms are published into Watson Knowledge Catalog. The category and business terms csvs files are included with the project.\n\nIn the second part of the notebook we programmatically publish a dataset into a catalog and map business terms to the dataset column headers. The business terms and their mappings are specified in a csv file included with the project. The user must first ensure that the catalog exists and the imported business terms have been published.\n\nThe user can also assign business terms to column headers manually or by using the Data Discovery capability within Cloud Pak for Data. \n\nThis notebook is optional. The analytics project runs as expected even if this notebook is not used. \n\n**Note that as only Admin users can import terms, this notebook should be run by an Admin user only.** User must have <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/catalog/roles-wkcop.html\" target=\"_blank\" rel=\"noopener noreferrer\">the permission to create governance artifacts."
        },
        {
            "metadata": {
                "id": "555ab750-fbe3-4f69-af51-a3b6bf575405"
            },
            "cell_type": "markdown",
            "source": "\n\nThe user should create a catalog and enter the following before running the rest of the notebook: \n\n **catalog_name :** Name of the catalog that we would like to publish the csv to. This catalog is created based on the instructions above or an existing catalog."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "catalog_name = 'Ind_Acc'",
            "execution_count": 28,
            "outputs": []
        },
        {
            "metadata": {
                "id": "2b77705f-a736-47ee-865e-720ae9cc054c"
            },
            "cell_type": "code",
            "source": "# imports for the rest APIs interactions with WKC\nimport requests\nfrom requests.packages.urllib3.exceptions import InsecureRequestWarning\nimport json\nrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)\nfrom pandas.io.json import json_normalize\nimport pandas as pd\nimport os\n\ns=requests.session()",
            "execution_count": 29,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## User Inputs\n1. **wkciamURL**: The url used to authenticate the ibm cloud api key.\n2. **wkcURL**: The base url used to call the apis of data platform.\n2. **categories_csv**: Name of the csv file containing the categories.\n3. **terms_csv**: Name of the csv file containing the business terms and their definitions.\n\nThe user does not need to change the code cell below, unless they run this notebook on a different environment or changed the name of the csv file with categories and business terms.\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# for dev, use https://iam.test.cloud.ibm.com/\n# for prod, use https://iam.cloud.ibm.com/\nwkciamURL=\"https://iam.cloud.ibm.com/\"\nwkcURLauth = wkciamURL+\"identity/token\"\n\nif os.environ['RUNTIME_ENV_REGION']=='us-south':\n    region=\"\"\nelse:\n    region=os.environ['RUNTIME_ENV_REGION']+\".\"\n\n# for dev, use \"https://api.\"+region+\"dataplatform.dev.cloud.ibm.com/\" \n# for prod use \"https://api.\"+region+\"dataplatform.cloud.ibm.com/\"\nwkcURL = \"https://api.\"+region+\"dataplatform.cloud.ibm.com/\"\n\n\ncategories_csv=\"retail-customer-retention-glossary-categories.csv\"\nterms_csv=\"retail-customer-retention-glossary-terms.csv\"\n\n\n",
            "execution_count": 30,
            "outputs": []
        },
        {
            "metadata": {
                "id": "7550bbd8-44e4-4005-81c1-a7034cff32c5"
            },
            "cell_type": "markdown",
            "source": "We also create additional variables. The user does not need to change the code cell below, unless they change the business terms category name or the name of the csv file with mappings.\n\n1. **category_name :** Name of the business term category corresponding to the project.\n2. **terms_file :** Name of the csv file containing the list of mappings between column headers and business terms.\n3. **data_asset_file_to_publish :** Name of the csv files that will be published into the catalog and for which we map business terms."
        },
        {
            "metadata": {
                "id": "525d7d38-cc01-44a5-8e13-3da74a619cfd"
            },
            "cell_type": "code",
            "source": "category_name = \"Retail Customer Retention\"\nterms_file = \"retail-customer-retention-map-terms.csv\" \ndata_asset_file_to_publish = [\"CUST_SURVEY_CHURN.csv\",\"CUST_SURVEYS.csv\"]",
            "execution_count": 31,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Authentication"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "IBM Cloud API key is used to authenticate and generate the bearer token in the below cell."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Headers\n\nheaders = { 'Content-Type': 'application/x-www-form-urlencoded', 'Accept': 'application/json'}\n\n# Payload with ibm cloud api key\npayload={\n    'apikey': ibmcloud_api_key,\n    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey'\n}\ntry:\n    authresponse = s.post(wkcURLauth, headers=headers,data=payload,verify=False)\n    if authresponse.status_code in (200,202):\n        print(\"Authentication Successful\")\n        accessToken=json.loads(authresponse.text)['access_token']\n    else:\n        print(\"Authentication unsuccessful, check your inputs\")\n        \n\nexcept:\n    print(\"The below error has occurred. Please ensure that api key entered is correct and user has access to watson knowledge catalog\")\n    raise",
            "execution_count": 32,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Authentication Successful\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Check WKC Plan"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The below cell checks users WKC plan using users account id."
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "code",
            "source": "try:\n    headers = {\n        'Content-Type': 'application/json',\n        'IAM-Apikey': ibmcloud_api_key,\n        'Authorization': 'Bearer '+accessToken\n    }\n\n    response = s.get(wkciamURL+'v1/apikeys/details', headers=headers)\n\n    account_id=json.loads(response.text)['account_id']\n\n    headers = {\n        'Authorization': 'Bearer '+accessToken,\n    }\n\n    response = s.get(wkcURL+'v2/entitlements?bss_account_id='+account_id, headers=headers)\n    wkc_plan=json.loads(response.text)['entitlements']['data_catalog']['plan_name']\n    print(\"Watson Knowldge Catalog Plan:\",wkc_plan)\n    \n    if(wkc_plan==\"Lite\"):\n        print(\"Lite plan detected - will attempt to publish 5 business terms only.\")\n    elif(wkc_plan==\"Standard\"):\n        print(\"Standard plan detected - will attempt to publish 150 business terms.\")\n        \nexcept:\n    print(\"The below error has occurred. Please ensure that api key entered is correct and user has access to watson knowledge catalog\")\n    raise",
            "execution_count": 33,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Watson Knowldge Catalog Plan: Standard\nStandard plan detected - will attempt to publish 150 business terms.\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 1. Import the Categories and Business terms \nIf the user is successfully authenticated, then we complete the following steps \n1. Read the business categories file and import the category `Retail Customer Retention` under `Industry Accelerators`\n2. Read the business terms file and import the business terms with definitions and related/part of terms for `Retail Customer Retention`.\n3. The imported business terms will be saved as a draft, publish the business terms programmatically. "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Import the Category"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Below cell reads catgories csv file and import the category `Retail Customer Retention` under `Industry Accelerators`.  "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "f = open(categories_csv, 'w+b')\nf.write(project.get_file(categories_csv).getbuffer())\nf.close()\n\n# Create a header\nimportheaders = {\n    'accept': 'application/json',\n    'Authorization': 'Bearer '+accessToken,  \n    'Content-Type': 'multipart/form-data'\n}\n\n# Specify merge option \nparams = (\n    ('merge_option', 'all'),\n)\n\n# remove the index\npd.read_csv(categories_csv).to_csv(categories_csv,index=False)\n\n# Specify the file name to import\nfiles = {\n    'file': (categories_csv, open(categories_csv, 'rb')),\n}\n\ntry:\n    categoryimport_url = wkcURL+'v3/governance_artifact_types/category/import'\n    cat_import = s.post(categoryimport_url, headers=importheaders, params=params, files=files)\n    if cat_import.status_code in (200,202):\n        print(\"Category import has\",json.loads(cat_import.text)['status'])\n    else:\n        print(\"Category import is unsuccessful,\", json.loads(cat_import.text)['errors'][0]['message'])\nexcept:\n    print(\"The below error has occurred. Please ensure that categories csv file exists\")\n    raise\n\n",
            "execution_count": 34,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Category import has SUCCEEDED\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Import Business terms"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Read the business terms file and import the business terms with definitions and related/part of terms for `Retail Customer Retention`. `Lite` plan users can import only 5 business terms into watson knowledge catalog. `Standard` plan users can import upto 150 business terms. If the user already has business terms, delete them before running below cell. \n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "f = open(terms_csv, 'w+b')\nf.write(project.get_file(terms_csv).getbuffer())\nif wkc_plan==\"Lite\":\n    \n\n    filter_rows_by_account_type=pd.read_csv(terms_csv)\n    map_terms_file = project.get_file(terms_file)\n    map_terms_file.seek(0)\n    map_terms = pd.read_csv(map_terms_file)\n    filter_rows_by_account_type=filter_rows_by_account_type[filter_rows_by_account_type['Name'].isin(map_terms['Business Terms'].tolist())].head()\n    filter_rows_by_account_type.to_csv(terms_csv,index=False)\nprint(\"Watson Knowldge Catalog Plan:\",wkc_plan)\nprint(\"Maximum number of business terms allowed to import and publish:\",json.loads(response.text)['entitlements']['data_catalog']['properties']['business_glossary']['max_terms'])\n\nf.close()\n\npd.read_csv(terms_csv).to_csv(terms_csv,index=False)\n\nfiles = {\n    'file': (terms_csv, open(terms_csv, 'rb')),\n}\n\ntry:\n    termsimport_url =wkcURL+'v3/governance_artifact_types/glossary_term/import'\n    term_import = s.post(termsimport_url, headers=importheaders, params=params, files=files)\n    if term_import.status_code in (200,202):\n        wf_json=json.loads(term_import.text)\n        print(\"Business Terms import has\",wf_json['status'])\n        print(\"Number of Business terms imported:\",max(json.loads(term_import.text)['operations_count']['glossary_term']['IMPORT_MODIFY'],json.loads(term_import.text)['operations_count']['glossary_term']['IMPORT_CREATE']))\n    else:\n        print(\"Import of Business Terms failed.\")\n        raise Exception(json.loads(term_import.text)['errors'][0]['message'])\nexcept:\n    print(\"The below error has occurred. Please check your WKC plan and Business Terms csvs\")\n    print(json.loads(term_import.text)['messages']['resources'])\n    raise\n\n",
            "execution_count": 35,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Watson Knowldge Catalog Plan: Standard\nMaximum number of business terms allowed to import and publish: 150\nBusiness Terms import has SUCCEEDED\nNumber of Business terms imported: 53\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "#### Fetch imported terms draft and publish the terms"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "If the business terms are successfully imported in the previous cell, the imported business terms have been saved in draft status. The below cell publishes the business terms."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "headers = {\n'Content-Type': \"application/json\",\n'Authorization': \"Bearer \"+accessToken\n\n}\ntry:\n    wf_url=wkcURL+\"v3/workflows/\"+wf_json['workflow_id']+\"?includeUserTasks=true\"\n    wf_response=s.get(wf_url,headers=headers)\n    if wf_response.status_code in (200,202):\n        idtopublish=json.loads(wf_response.text)['entity']['user_tasks'][0]['metadata']['task_id']\nexcept:\n    print(\"The below error has occurred. Please ensure that terms are imported correctly\")\n    raise    \n    \n    \n## Publish the Business terms\ndata = {\n    \"action\": \"complete\",\n    \"form_properties\": [\n        {\n            \"id\": \"action\",\n            \"value\": \"#publish\"\n        }\n    ]\n}\npublish_url=wkcURL+'v3/workflow_user_tasks/'+idtopublish+'/actions'\n\n\ntry:\n    publish = s.post(publish_url, headers=headers, json=data, verify=False)\n\n    if publish.status_code in (200,202,204):\n        print(\"The Business terms have been successfully published.\")\nexcept:\n    print(\"The below error has occurred. Please ensure that terms are imported correctly\")\n    raise\n    \n",
            "execution_count": 36,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "The Business terms have been successfully published.\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "When the Business terms are published, navigate to **Governance -> Categories -> Industry Accelerators** to find the category and business terms pertaining to this accelerator.\n"
        },
        {
            "metadata": {
                "id": "09f5625b-53ed-45c6-9759-61b318e1a193"
            },
            "cell_type": "markdown",
            "source": "## 2. Map Business Terms to Data Headers\nIn this part of the notebook, we take the published business terms and map them to the dataset column headers\n### Create Catalog\n\nThe dataset must first be published into a catalog. The catalog must be manually created. Under **Catalogs** in the navigation menu, select **All Catalogs** and select **New Catalog**. Enter the name for the catalog and the description if necessary and create the catalog. If the user has already created the catalog this step can be skipped and the existing catalog name should be specified in the code cell below.\n"
        },
        {
            "metadata": {
                "id": "fe7690d6-79bf-4c63-b928-c90014fa17e3"
            },
            "cell_type": "markdown",
            "source": "## Map Business Terms to Headers\n\nWe complete the following steps to map the business terms to column headers:\n\n1. Check if the Category `Retail Customer Retention` exists in the parent category `Industry Accelerators`.\n2. Load the business terms from the `Retail Customer Retention` subcategory into a dataframe.\n3. Publish the specified dataset into the catalog.\n4. Assign business terms to the dataset column headers."
        },
        {
            "metadata": {
                "id": "bc76fd44-da4d-4d22-ae9d-58069ade50ae"
            },
            "cell_type": "markdown",
            "source": "### 1. Check for the Category"
        },
        {
            "metadata": {
                "id": "e069e904-f9e8-4e0b-80e3-f6f2ee579863"
            },
            "cell_type": "code",
            "source": "search_url=wkcURL+\"v3/search\"\ntry:\n    headers = {\n        'Content-Type': \"application/json\",\n        'Authorization': \"Bearer \"+accessToken,\n        'Cache-Control': \"no-cache\",\n        'Connection': \"keep-alive\"\n        }\n    \n    search_body = {\n        \"size\": 1000,\n        \"_source\": [\"artifact_id\",\"metadata.name\"],\n       \"query\": {    \n               \"match\": {\"metadata.artifact_type\": \"category\"}\n       }\n    }\n    parent_cat = s.post(search_url, verify=False,  json=search_body, headers=headers)\n    \n    \n    \n    # Check if Industry accelerator category exists and load its id into a variable `parent_id`\n    if parent_cat.status_code == 200:\n        category=json.loads(parent_cat.text)\n        for i in category['rows']:\n            \n            if i['metadata']['name']== category_name:\n                print(\"Category \",category_name,\"exists\")\n\n                exists_category=True\n                cat_id=i['artifact_id'] \n                category_id=cat_id[cat_id.index('_')+1:][:cat_id.index('_')]\n            \n                   \nexcept:\n    print(\"The below error has occurred. \" + \"Please ensure that category, '\" + category_name + \"', exists.\")\n    raise ValueError(parent_cat.text)",
            "execution_count": 37,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Category  Retail Customer Retention exists\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {
                "id": "9244268a-3de7-438c-825b-be1efcb8f025"
            },
            "cell_type": "markdown",
            "source": "### 2. Load category Business Terms into Dataframe "
        },
        {
            "metadata": {
                "id": "a7bcbdd0-c9e3-4a41-be06-a5f1d9283639"
            },
            "cell_type": "markdown",
            "source": "Get all of the terms in the `Retail Customer Retention` category and store them in the `df_terms` dataframe."
        },
        {
            "metadata": {
                "id": "ee7977ec-42af-4761-87d9-e516364f7c42"
            },
            "cell_type": "code",
            "source": "# Create a payload for the post request, This payload contains information on size of the terms, source, category and subcategory ids\npayload={\"size\":300,\"from\":0,\"_source\":[\"artifact_id\",\"metadata.artifact_type\",\"metadata.name\",\"metadata.description\",\"categories\",\"entity.artifacts\"],\"query\":{\"bool\":{\"filter\":{\"bool\":{\"minimum_should_match\":1,\"should\":[{\"term\":{\"categories.primary_category_id\":category_id}},{\"term\":{\"categories.secondary_category_ids\":category_id}}],\"must_not\":{\"terms\":{\"metadata.artifact_type\":[\"category\"]}}}}}}}\n# create a post request with above payload \nwf=s.post(wkcURL+\"v3/search\",headers=headers,json=payload,verify=False)\n# it will return all the terms , load these terms into a dataframe\nwf_json=json.loads(wf.text)['rows']\ndf_terms=pd.json_normalize(wf_json)\n\ndf_terms=df_terms[['entity.artifacts.global_id','metadata.name']]",
            "execution_count": 38,
            "outputs": []
        },
        {
            "metadata": {
                "id": "b0b99115-47b2-41c4-916d-63816b66cf9b"
            },
            "cell_type": "code",
            "source": "# terms dataframe looks as below\ndf_terms.head()",
            "execution_count": 39,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 39,
                    "data": {
                        "text/plain": "                          entity.artifacts.global_id  \\\n0  b1eaa887-5aa8-4be6-a22b-3601457590d4_445e3a74-...   \n1  b1eaa887-5aa8-4be6-a22b-3601457590d4_7d08709b-...   \n2  b1eaa887-5aa8-4be6-a22b-3601457590d4_179de939-...   \n3  b1eaa887-5aa8-4be6-a22b-3601457590d4_830be681-...   \n4  b1eaa887-5aa8-4be6-a22b-3601457590d4_c5916a7f-...   \n\n               metadata.name  \n0          Order Method Type  \n1                Sales Store  \n2                  Unit Cost  \n3               Price Rating  \n4  Distance to Nearest Store  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entity.artifacts.global_id</th>\n      <th>metadata.name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b1eaa887-5aa8-4be6-a22b-3601457590d4_445e3a74-...</td>\n      <td>Order Method Type</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b1eaa887-5aa8-4be6-a22b-3601457590d4_7d08709b-...</td>\n      <td>Sales Store</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b1eaa887-5aa8-4be6-a22b-3601457590d4_179de939-...</td>\n      <td>Unit Cost</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b1eaa887-5aa8-4be6-a22b-3601457590d4_830be681-...</td>\n      <td>Price Rating</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b1eaa887-5aa8-4be6-a22b-3601457590d4_c5916a7f-...</td>\n      <td>Distance to Nearest Store</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "id": "d2dc55a5-ac20-4e53-87f9-5eff82f209d2"
            },
            "cell_type": "markdown",
            "source": "### 3. Publish Dataset into Catalog"
        },
        {
            "metadata": {
                "id": "012c2592-1204-4555-8ce2-65b9feb3f61d"
            },
            "cell_type": "markdown",
            "source": "Get the ID of the catalog that was specified in the user inputs at the beginning of this notebook."
        },
        {
            "metadata": {
                "id": "84d7683e-ad57-40af-92fa-a7d986d55da8"
            },
            "cell_type": "code",
            "source": "## Get catalog that created and its id by providing name of the catalog created, wich should be same as the one entered in the previous cells\ncatalog_endpoint=wkcURL+\"v2/catalogs\"\n# Create new header for the requests\nheaders = {\n'Content-Type': \"application/json\",\n'Authorization': \"Bearer \"+accessToken\n\n}\n\n# endpoint to get all the catalogs \nget_catalog=s.get(catalog_endpoint,verify=False, headers=headers)\n\n\n## Find the catalog created with specific name and store name and id of it into catalog_name and catalog_id respectively\ntry:\n    get_catalog_json=json.loads(get_catalog.text)['catalogs']\nexcept:\n    print(\"The below error has occurred. Please ensure that catalog, '\" + catalog_name + \"', exists\")\n    raise\n    \ncatalog_id = ''\nfor metadata in get_catalog_json:\n    if metadata['entity']['name']==catalog_name:\n        catalog_id=metadata['metadata']['guid']\n        print(\"catalog_id for\",catalog_name, catalog_id)\n\nif catalog_id == '':\n    print(\"The provided catalog name cannot be found. Please ensure that catalog, '\" + catalog_name + \"', exists\")\n    raise ValueError(\"Catalog cannot be found\")",
            "execution_count": 40,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "catalog_id for Ind_Acc f559304b-2f00-417e-969d-560e07787113\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {
                "id": "7ee24dea-5d53-405f-9470-4a2ca95c6a42"
            },
            "cell_type": "markdown",
            "source": "Get the project id. All project assets can be accessed using this project id."
        },
        {
            "metadata": {
                "id": "3ef5237d-f93a-4fa4-95ba-23dcf2319ff4"
            },
            "cell_type": "code",
            "source": "# Enter project_id manually if referring to a different project\nproject_id=os.environ['PROJECT_ID']",
            "execution_count": 41,
            "outputs": []
        },
        {
            "metadata": {
                "id": "801c5911-6376-40a2-8be4-0db67d09e59a"
            },
            "cell_type": "markdown",
            "source": "Get all existing csv files in the project folder and store the names of these files. "
        },
        {
            "metadata": {
                "id": "cb58b2a8-e22c-4cd0-a3aa-0b3145998983"
            },
            "cell_type": "code",
            "source": "# payload \npayload={\"query\":\"*:*\",\"limit\":200}\n# endpoint to access all the project assets in the project folder \nasset_url=wkcURL+\"v2/asset_types/asset/search?project_id=\"+project_id\nget_asset=s.post(asset_url,json=payload,verify=False)",
            "execution_count": 42,
            "outputs": []
        },
        {
            "metadata": {
                "id": "11f18280-bda0-4f50-b011-8ede6b6ef4d0"
            },
            "cell_type": "markdown",
            "source": "Next we get the asset id of the dataset to be published to the catalog."
        },
        {
            "metadata": {
                "id": "07410db9-6e39-478e-ab26-9b3e366e038a"
            },
            "cell_type": "code",
            "source": "# Get asset ids of all csv files to be published in to the catalog and store the asset ids in an array\n\nproject_asset_id=[]\n# Payload to query all project assets\npayload={\"query\":\"*:*\",\"limit\":200}\n\nget_asset=s.post(wkcURL+\"v2/asset_types/asset/search?project_id=\"+project_id,json=payload,verify=False, headers=headers)\nget_asset_json=json.loads(get_asset.text)\nfor j in get_asset_json['results']:\n    if j['metadata']['name'] in data_asset_file_to_publish:\n        print(\"Asset id of\",j['metadata']['name'],\":\",j['metadata']['asset_id'])\n        project_asset_id.append(j['metadata']['asset_id'])",
            "execution_count": 43,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Asset id of CUST_SURVEY_CHURN.csv : 00a44cc9-d497-4883-b18e-d6e4a515d205\nAsset id of CUST_SURVEYS.csv : bae42d4e-3577-4601-9b14-edb05ad49317\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {
                "id": "60276fcc-c95c-4d2b-889c-4867d90bcea0"
            },
            "cell_type": "markdown",
            "source": "Using the asset ID for the dataset, upload the dataset into the catalog using the post request below. Get the new asset ID of the newly published dataset."
        },
        {
            "metadata": {
                "id": "a6377d1e-9839-4aed-bda1-8957d930d083"
            },
            "cell_type": "code",
            "source": "print(\"ASSET ID's of the published assets\")\n# Creates a empty dictionary\ncatalog_asset_ids={}\nfor asset_id in project_asset_id:\n    #for  each asset in the project , publish them into the catalog \n    # pyload to publish the asset\n    payload={\"mode\":0,\"catalog_id\":catalog_id,\"metadata\":{}}\n    # endpoint to publish asset\n    asset_publish_url=wkcURL+\"v2/assets/\"+asset_id+\"/publish?project_id=\"+project_id\n    # Post request with endpoint, heaeder and payload\n    publishasset=requests.post(asset_publish_url,json=payload,headers=headers,verify=False)\n    # api endpoint returns below text\n    publishasset_json=json.loads(publishasset.text)\n    # extract csv file published and its asset id and append it to the dictionary\n    catalog_asset_ids[publishasset_json['metadata']['name']]=publishasset_json['asset_id']\n    \nprint(catalog_asset_ids)",
            "execution_count": 44,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "ASSET ID's of the published assets\n{'CUST_SURVEY_CHURN.csv': '483a44d2-0fdf-4c0d-aab6-cbded2e31317', 'CUST_SURVEYS.csv': '21ea5176-f4d3-4984-bedb-dfa40de66b51'}\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {
                "id": "e463a7c6-0797-4b98-9cb7-f8f355961b01"
            },
            "cell_type": "markdown",
            "source": "### 4. Assign Business Terms to Column Headers\n\nRead in the file with business terms and their associated column headers and view a sample of the data."
        },
        {
            "metadata": {
                "id": "7ab5a402-b610-40d1-8875-3fea9e3d953f"
            },
            "cell_type": "code",
            "source": "map_terms_file = project.get_file(terms_file)\nmap_terms_file.seek(0)\nmap_terms = pd.read_csv(map_terms_file)\n\nprint(map_terms.shape)\nmap_terms.head()",
            "execution_count": 45,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "(21, 5)\n",
                    "name": "stdout"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 45,
                    "data": {
                        "text/plain": "           Business Terms  Column_header                      Table  \\\n0               Age Group            Age  Retail Customer Retention   \n1        Attrition Status     IS_CHURNER  Retail Customer Retention   \n2      Cleanliness Rating  Q_cleanliness  Retail Customer Retention   \n3  Customer Annual Income         Income  Retail Customer Retention   \n4        Customer Expense    Money_spent  Retail Customer Retention   \n\n                File  Unnamed: 4  \n0       CUST_SURVEYS         NaN  \n1  CUST_SURVEY_CHURN         NaN  \n2       CUST_SURVEYS         NaN  \n3       CUST_SURVEYS         NaN  \n4       CUST_SURVEYS         NaN  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Business Terms</th>\n      <th>Column_header</th>\n      <th>Table</th>\n      <th>File</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Age Group</td>\n      <td>Age</td>\n      <td>Retail Customer Retention</td>\n      <td>CUST_SURVEYS</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Attrition Status</td>\n      <td>IS_CHURNER</td>\n      <td>Retail Customer Retention</td>\n      <td>CUST_SURVEY_CHURN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cleanliness Rating</td>\n      <td>Q_cleanliness</td>\n      <td>Retail Customer Retention</td>\n      <td>CUST_SURVEYS</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Customer Annual Income</td>\n      <td>Income</td>\n      <td>Retail Customer Retention</td>\n      <td>CUST_SURVEYS</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Customer Expense</td>\n      <td>Money_spent</td>\n      <td>Retail Customer Retention</td>\n      <td>CUST_SURVEYS</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "id": "22fe64dc-5f01-4d74-a658-b251858d3234"
            },
            "cell_type": "code",
            "source": "df_terms.head()\n\n",
            "execution_count": 46,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 46,
                    "data": {
                        "text/plain": "                          entity.artifacts.global_id  \\\n0  b1eaa887-5aa8-4be6-a22b-3601457590d4_445e3a74-...   \n1  b1eaa887-5aa8-4be6-a22b-3601457590d4_7d08709b-...   \n2  b1eaa887-5aa8-4be6-a22b-3601457590d4_179de939-...   \n3  b1eaa887-5aa8-4be6-a22b-3601457590d4_830be681-...   \n4  b1eaa887-5aa8-4be6-a22b-3601457590d4_c5916a7f-...   \n\n               metadata.name  \n0          Order Method Type  \n1                Sales Store  \n2                  Unit Cost  \n3               Price Rating  \n4  Distance to Nearest Store  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entity.artifacts.global_id</th>\n      <th>metadata.name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b1eaa887-5aa8-4be6-a22b-3601457590d4_445e3a74-...</td>\n      <td>Order Method Type</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b1eaa887-5aa8-4be6-a22b-3601457590d4_7d08709b-...</td>\n      <td>Sales Store</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b1eaa887-5aa8-4be6-a22b-3601457590d4_179de939-...</td>\n      <td>Unit Cost</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b1eaa887-5aa8-4be6-a22b-3601457590d4_830be681-...</td>\n      <td>Price Rating</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b1eaa887-5aa8-4be6-a22b-3601457590d4_c5916a7f-...</td>\n      <td>Distance to Nearest Store</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "id": "1d3cd2f2-91d5-4a0e-8861-10523c361337"
            },
            "cell_type": "markdown",
            "source": "Join the `df_terms` and `map_terms` dataframes and map each column header to a business term. The code below loops through each file in the catalog (one file in our case) and performs the following tasks:\n\n1. Create a dataframe with column headers in the catalog and associated business term and term ids.\n2. Fetch catalog asset id for each csv in the catalog.\n3. Create a column_info attribute for all the files in the catalog.\n4. Map column header to the business terms. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "patch_attribute.status_code",
            "execution_count": 49,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 49,
                    "data": {
                        "text/plain": "200"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "id": "a316a7f1-630b-4400-839e-c95182838cb6",
                "scrolled": true
            },
            "cell_type": "code",
            "source": "# For every file in the map terms csv do the following\n# Join the csv with specified file name with the published terms to get its term id\n# drop if any duplicates found to avoid multiple mappings for the same term\n\n#map_terms=map_terms[map_terms['File']==file]\nmap_terms=map_terms.sort_values(by=['File','Column_header'])\nTerms_Headers=pd.merge(map_terms,df_terms,left_on='Business Terms',right_on='metadata.name',how='inner')\nTerms_Headers=Terms_Headers.drop_duplicates()\n\nfor file in catalog_asset_ids:#map_terms.File.unique():\n    # Catalog asset id of the particular csvs\n    # for each file name in the map_terms if the csv with this file name exists, get its asset_id from the catalog and use the post request publish create column_info attribute\n    # This column info attribute is necessary to map the busines terms to column to header\n    \n\n    catalog_asset_id=catalog_asset_ids[file]\n    print(file,  catalog_asset_id)\n    #### \n    payload={\"name\": \"column_info\",\n       \"entity\":{\n                  #\"sample_size\":50\n               }\n    }\n    t=requests.post(wkcURL+\"v2/assets/\"+catalog_asset_id+\"/attributes?catalog_id=\"+catalog_id,json=payload,headers=headers,verify=False)\n    #print(t.text)\n    # For each column header in the file map its corresponding business term retrieved from the above join in the dataframe\n\n    i=0\n    for index, rows in Terms_Headers.iterrows(): \n      \n        # Create list for the current row \n        # Below payload is used for the patch request to map the  header to business terms\n        payload=[{\"op\":\"add\",\"path\":\"/\"+rows.Column_header.strip(),\"value\":{\"column_terms\":[{\"term_display_name\":rows['Business Terms'],\"term_id\":rows[\"entity.artifacts.global_id\"]}]},\"attribute\":\"column_info\"}]\n    #\n        # Endpoint for patch request\n        url=wkcURL+\"v2/assets/\"+catalog_asset_id+\"/attributes/column_info?catalog_id=\"+catalog_id\n    # patch request to map busines terms to column header using term_id\n        patch_attribute=s.patch(url,json=payload,headers=headers,verify=False)\n        if (patch_attribute.status_code==200):\n            i+=1\n            print(i,rows.Column_header.strip(), \"is mapped to\", rows['Business Terms'])\n            \n    #\n        ",
            "execution_count": 54,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "CUST_SURVEY_CHURN.csv 483a44d2-0fdf-4c0d-aab6-cbded2e31317\n1 Age is mapped to Age Group\n2 Gender is mapped to Gender\n3 ID is mapped to Customer Identifier\n4 ID is mapped to Customer Identifier\n5 Income is mapped to Customer Annual Income\n6 Items_bought is mapped to Products Purchased\n7 Member is mapped to Membership Indicator\n8 Money_spent is mapped to Customer Expense\n9 Nearest store is mapped to Distance to Nearest Store\n10 Occupation is mapped to Occupation\n11 Q_cleanliness is mapped to Cleanliness Rating\n12 Q_price is mapped to Price Rating\n13 Q_promotions is mapped to Promotion Rating\n14 Q_store_ambiance is mapped to Store Ambience Rating\n15 Q_store_products_options is mapped to Store Product Options Rating\n16 Q_store_quality is mapped to Store Quality Rating\n17 Q_store_service is mapped to Store Service Rating\n18 Store_visit_frequency is mapped to Visit Frequency\n19 Time_spent is mapped to Time Spent\n20 Visit_type is mapped to Customer Visit Type\n21 IS_CHURNER is mapped to Attrition Status\nCUST_SURVEYS.csv 21ea5176-f4d3-4984-bedb-dfa40de66b51\n1 Age is mapped to Age Group\n2 Gender is mapped to Gender\n3 ID is mapped to Customer Identifier\n4 ID is mapped to Customer Identifier\n5 Income is mapped to Customer Annual Income\n6 Items_bought is mapped to Products Purchased\n7 Member is mapped to Membership Indicator\n8 Money_spent is mapped to Customer Expense\n9 Nearest store is mapped to Distance to Nearest Store\n10 Occupation is mapped to Occupation\n11 Q_cleanliness is mapped to Cleanliness Rating\n12 Q_price is mapped to Price Rating\n13 Q_promotions is mapped to Promotion Rating\n14 Q_store_ambiance is mapped to Store Ambience Rating\n15 Q_store_products_options is mapped to Store Product Options Rating\n16 Q_store_quality is mapped to Store Quality Rating\n17 Q_store_service is mapped to Store Service Rating\n18 Store_visit_frequency is mapped to Visit Frequency\n19 Time_spent is mapped to Time Spent\n20 Visit_type is mapped to Customer Visit Type\n21 IS_CHURNER is mapped to Attrition Status\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {
                "id": "45c53353-0a0a-4bf1-abab-b223a2a485c4"
            },
            "cell_type": "markdown",
            "source": "The specified dataset is now published to the catalog and its column headers are mapped to their associated business terms. \n\nNavigate to the business terms or the catalog data asset to view the mappings created.\n\nThe associated business term for the column header is displayed."
        },
        {
            "metadata": {
                "id": "41555d4a-2148-43c5-858f-41a0cefbb6da"
            },
            "cell_type": "code",
            "source": "s.close()",
            "execution_count": 48,
            "outputs": []
        },
        {
            "metadata": {
                "id": "2b5e4ffa8d3d481e87ebd4d626a56c9d"
            },
            "cell_type": "markdown",
            "source": "<hr>\n\nSample Materials, provided under <a href=\"https://github.com/IBM/Industry-Accelerators/blob/master/CPD%20SaaS/LICENSE\" target=\"_blank\" rel=\"noopener noreferrer\">license.</a> <br>\nLicensed Materials - Property of IBM. <br>\n\u00a9 Copyright IBM Corp. 2020, 2021. All Rights Reserved. <br>\nUS Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp. <br>"
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.12",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}